# -*- coding: utf-8 -*-
"""retina blood sugar

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-4Xu0SFBgk5AZZmPrFE3O2TqX3mj0xhx
"""

!pip install tensorflow keras numpy pandas matplotlib scikit-learn opencv-python

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
import cv2
import os
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.applications import VGG16
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split

# Set the dataset directory
dataset_dir = "/content/retina_dataset/train_images"

# Function to load and preprocess images
def load_images_and_labels(dataset_dir, img_size=(224, 224)):
    images = []
    labels = []

    for filename in os.listdir(dataset_dir):
        if filename.endswith(".jpg") or filename.endswith(".png"):
            img_path = os.path.join(dataset_dir, filename)
            img = cv2.imread(img_path)
            img = cv2.resize(img, img_size)  # Resize to match model input size
            img = img / 255.0  # Normalize pixel values

            # Extract blood sugar level from filename (Assume format: "image_120.jpg")
            sugar_level = int(filename.split("_")[-1].split(".")[0])

            images.append(img)
            labels.append(sugar_level)

    return np.array(images), np.array(labels)

# Load images
X, y = load_images_and_labels(dataset_dir)

# Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("Dataset Loaded! Training Samples:", X_train.shape[0], "Testing Samples:", X_test.shape[0])

"""# New Section"""

# Import necessary libraries
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.models import load_model
from google.colab import files  # For uploading files in Colab

# Step 1: Upload the Retinal Image
def upload_image():
    """
    Uploads a retinal image using Google Colab's file uploader.
    """
    uploaded = files.upload()
    for filename in uploaded.keys():
        print(f"Image '{filename}' uploaded successfully.")
        return filename
    raise ValueError("No image uploaded. Please upload a retinal image.")

# Step 2: Preprocess the Uploaded Image
def preprocess_image(image_path, target_size=(68, 68)):
    """
    Preprocesses the retinal image for the model.
    """
    try:
        img = Image.open(image_path).convert('RGB')  # Ensure RGB mode
        img = img.resize(target_size)  # Resize to target size
        img_array = np.array(img) / 255.0  # Normalize to [0, 1]
        img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension
        return img_array
    except Exception as e:
        raise ValueError(f"Error processing image: {e}")

# Step 3: Load the Pre-trained Model
def load_pretrained_model(model_path='retinal_blood_sugar_model.h5'):
    """
    Loads the pre-trained model for blood sugar level prediction.
    """
    try:
        model = load_model(model_path)
        print("Pre-trained model loaded successfully.")
        return model
    except Exception as e:
        raise ValueError(f"Error loading model: {e}")

# Step 4: Predict Blood Sugar Level
def predict_blood_sugar(model, image):
    """
    Predicts the blood sugar level from the preprocessed retinal image.
    """
    try:
        predicted_blood_sugar = model.predict(image, batch_size=1, verbose=0)[0][0]
        return predicted_blood_sugar
    except Exception as e:
        raise ValueError(f"Error predicting blood sugar level: {e}")

# Step 5: Display the Result
def display_result(image, predicted_blood_sugar):
    """
    Displays the uploaded retinal image and the predicted blood sugar level.
    """
    plt.imshow(image[0])  # Remove batch dimension for display
    plt.title(f"Predicted Blood Sugar Level: {predicted_blood_sugar:.2f} mg/dL")
    plt.axis('off')
    plt.show()

# Main Function
def main():
    # Step 0: Upload the Pre-trained Model
    print("Please upload the pre-trained model file (retinal_blood_sugar_model.h5).")
    from google.colab import files
    uploaded_model = files.upload()
    model_path = list(uploaded_model.keys())[0]  # Get the uploaded model file name

    # Step 1: Upload the Retinal Image
    print("Please upload a retinal image (JPEG or PNG format).")
    image_path = upload_image()

    # Step 2: Preprocess the Uploaded Image
    try:
        print("Preprocessing image...")
        image = preprocess_image(image_path)
        print("Image successfully processed.")
    except Exception as e:
        print(e)
        return

    # Step 3: Load the Pre-trained Model
    try:
        print("Loading pre-trained model...")
        model = load_pretrained_model(model_path)
    except Exception as e:
        print(e)
        return

    # Step 4: Predict Blood Sugar Level
    try:
        print("Predicting blood sugar level...")
        predicted_blood_sugar = predict_blood_sugar(model, image)
        print(f"Predicted Blood Sugar Level: {predicted_blood_sugar:.2f} mg/dL")
    except Exception as e:
        print(e)
        return

    # Step 5: Display the Result
    print("Displaying result...")
    display_result(image, predicted_blood_sugar)

# Run the program
if __name__ == "__main__":
    main()

# Import necessary libraries
import numpy as np
from PIL import Image
import tensorflow as tf
from tensorflow.keras import layers, models
from google.colab import files
import matplotlib.pyplot as plt

# Step 1: Upload a retinal image (JPEG format)
print("Please upload your retinal image (JPEG format).")
uploaded = files.upload()

# Check if any file was uploaded
if not uploaded:
    raise ValueError("No file uploaded. Please upload an image.")

# Get the uploaded file name
image_file = list(uploaded.keys())[0]

# Step 2: Load and preprocess the image
def preprocess_image(image_path, target_size=(68, 68)):
    try:
        img = Image.open(image_path).convert('RGB')  # Ensure RGB mode
        img = img.resize(target_size)
        img_array = np.array(img) / 255.0  # Normalize to [0, 1]
        img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension
        return img_array
    except Exception as e:
        raise ValueError(f"Error processing image: {e}")

# Preprocess the uploaded image
try:
    image = preprocess_image(image_file)
    print("Image successfully processed.")
except Exception as e:
    print(f"Error: {e}")
    raise

# Step 3: Save the preprocessed image as a .npy file
np.save('retinal_image.npy', image)
print("Image saved as 'retinal_image.npy'.")

# Step 4: Build a CNN model for blood sugar prediction
def build_model(input_shape):
    model = models.Sequential([
        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(128, (3, 3), activation='relu'),
        layers.Flatten(),
        layers.Dense(128, activation='relu'),
        layers.Dense(1)  # Output layer for regression (predicting blood sugar level)
    ])
    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])
    return model

# Define input shape based on the preprocessed image
input_shape = image.shape[1:]  # Shape of a single image (e.g., 68, 68, 3)

# Build the model
model = build_model(input_shape)

# Step 5: Load pre-trained weights (if available)
pretrained_model_path = 'pretrained_model.h5'  # Change this to your trained model file

try:
    model.load_weights(pretrained_model_path)
    print("Pre-trained model weights loaded successfully.")
except Exception as e:
    print(f"Warning: Could not load pre-trained weights. The model is untrained. Error: {e}")

# Step 6: Predict the blood sugar level
predicted_blood_sugar = model.predict(image)[0][0]

# Step 7: Display the result
print(f"\nPredicted Blood Sugar Level: {predicted_blood_sugar:.2f} mg/dL")

# Step 8: Display the uploaded image
plt.imshow(image[0])  # Remove batch dimension for display
plt.title(f"Predicted Blood Sugar Level: {predicted_blood_sugar:.2f} mg/dL")
plt.axis('off')
plt.show()

# Import necessary libraries
import numpy as np
from PIL import Image
import tensorflow as tf
from tensorflow.keras import layers, models
from google.colab import files
import matplotlib.pyplot as plt

# Step 1: Upload a retinal image (JPEG format)
print("Please upload your retinal image (JPEG format).")
uploaded = files.upload()

# Check if any file was uploaded
if not uploaded:
    raise ValueError("No file uploaded. Please upload an image.")

# Get the uploaded file name
image_file = list(uploaded.keys())[0]

# Step 2: Load and preprocess the image
def preprocess_image(image_path, target_size=(68, 68)):
    try:
        img = Image.open(image_path).convert('RGB')  # Ensure RGB mode
        img = img.resize(target_size)
        img_array = np.array(img) / 255.0  # Normalize to [0, 1]
        img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension
        return img_array
    except Exception as e:
        raise ValueError(f"Error processing image: {e}")

# Preprocess the uploaded image
try:
    image = preprocess_image(image_file)
    print("Image successfully processed.")
except Exception as e:
    print(f"Error: {e}")
    raise

# Step 3: Save the preprocessed image as a .npy file
np.save('retinal_image.npy', image)
print("Image saved as 'retinal_image.npy'.")

# Step 4: Build a CNN model for blood sugar prediction
def build_model(input_shape):
    model = models.Sequential([
        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(128, (3, 3), activation='relu'),
        layers.Flatten(),
        layers.Dense(128, activation='relu'),
        layers.Dense(1)  # Output layer for regression (predicting blood sugar level)
    ])
    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])
    return model

# Define input shape based on the preprocessed image
input_shape = image.shape[1:]  # Shape of a single image (e.g., 68, 68, 3)

# Build the model
model = build_model(input_shape)

# Step 5: Load pre-trained weights (if available)
pretrained_model_path = "trained_model.weights.h5"

try:
    model.load_weights(pretrained_model_path)
    print("✅ Pre-trained model weights loaded successfully.")
except Exception as e:
    print(f"⚠️ Warning: Could not load pre-trained weights. The model is untrained. Error: {e}")

    # Step 6: Train the model if no weights are found
    print("⏳ Training the model...")

    # Generate dummy training data (Replace this with actual dataset)
    num_samples = 1000
    X_train = np.random.rand(num_samples, 68, 68, 3)  # Random images
    y_train = np.random.rand(num_samples) * 200  # Random blood sugar levels (0-200 mg/dL)

    model.fit(X_train, y_train, epochs=10, batch_size=16)

    # Save the trained model
    model.save_weights(pretrained_model_path)
    print("✅ Model trained and saved as 'trained_model.h5'.")

# Step 7: Predict the blood sugar level
predicted_blood_sugar = model.predict(image)[0][0]

# Step 8: Display the result
print(f"\n🔍 Predicted Blood Sugar Level: {predicted_blood_sugar:.2f} mg/dL")

# Step 9: Display the uploaded image with the prediction
plt.imshow(image[0])  # Remove batch dimension for display
plt.title(f"Predicted Blood Sugar Level: {predicted_blood_sugar:.2f} mg/dL")
plt.axis('off')
plt.show()

# Import necessary libraries
import numpy as np
from PIL import Image
import tensorflow as tf
from tensorflow.keras import layers, models
from google.colab import files
import matplotlib.pyplot as plt

# Step 1: Upload a retinal image (JPEG format)
print("Please upload your retinal image (JPEG format).")
uploaded = files.upload()

# Check if any file was uploaded
if not uploaded:
    raise ValueError("No file uploaded. Please upload an image.")

# Get the uploaded file name
image_file = list(uploaded.keys())[0]

# Step 2: Load and preprocess the image
def preprocess_image(image_path, target_size=(68, 68)):
    try:
        img = Image.open(image_path).convert('RGB')  # Ensure RGB mode
        img = img.resize(target_size)
        img_array = np.array(img) / 255.0  # Normalize to [0, 1]
        img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension
        return img_array
    except Exception as e:
        raise ValueError(f"Error processing image: {e}")

# Preprocess the uploaded image
try:
    image = preprocess_image(image_file)
    print("Image successfully processed.")
except Exception as e:
    print(f"Error: {e}")
    raise

# Step 3: Save the preprocessed image as a .npy file
np.save('retinal_image.npy', image)
print("Image saved as 'retinal_image.npy'.")

# Step 4: Build a CNN model for blood sugar prediction
def build_model(input_shape):
    model = models.Sequential([
        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(128, (3, 3), activation='relu'),
        layers.Flatten(),
        layers.Dense(128, activation='relu'),
        layers.Dense(1)  # Output layer for regression (predicting blood sugar level)
    ])
    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])
    return model

# Define input shape based on the preprocessed image
input_shape = image.shape[1:]  # Shape of a single image (e.g., 68, 68, 3)

# Build the model
model = build_model(input_shape)

# Step 5: Train the model (dummy training data for example purposes)
# Generate synthetic training data
X_train = np.random.rand(100, 68, 68, 3)  # 100 random images
y_train = np.random.rand(100) * 200  # 100 random blood sugar levels between 0-200 mg/dL

# Train the model
# model.fit(X_train, y_train, epochs=10, batch_size=10)
model.fit(X_train, y_train, epochs=50, batch_size=32)


# Step 6: Save the trained model
model_save_path = "trained_model.h5"  # Corrected filename for saving the full model
model.save(model_save_path)
print(f"✅ Model trained and saved as '{model_save_path}'.")

# Step 7: Load the trained model
model = tf.keras.models.load_model(model_save_path)
print("✅ Trained model loaded successfully.")

# Step 8: Predict the blood sugar level
predicted_blood_sugar = model.predict(image)[0][0]

# Step 9: Display the result
print(f"\nPredicted Blood Sugar Level: {predicted_blood_sugar:.2f} mg/dL")

# Step 10: Display the uploaded image
plt.imshow(image[0])  # Remove batch dimension for display
plt.title(f"Predicted Blood Sugar Level: {predicted_blood_sugar:.2f} mg/dL")
plt.axis('off')
plt.show()

import numpy as np
from PIL import Image
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.callbacks import EarlyStopping
import matplotlib.pyplot as plt
from google.colab import files

# Step 1: Upload a retinal image (JPEG format)
print("Please upload your retinal image (JPEG format).")
uploaded = files.upload()

# Check if any file was uploaded
if not uploaded:
    raise ValueError("No file uploaded. Please upload an image.")

# Get the uploaded file name
image_file = list(uploaded.keys())[0]

# Step 2: Load and preprocess the image
def preprocess_image(image_path, target_size=(68, 68)):
    try:
        img = Image.open(image_path).convert('RGB')
        img = img.resize(target_size)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        return img_array
    except Exception as e:
        raise ValueError(f"Error processing image: {e}")

# Preprocess the uploaded image
image = preprocess_image(image_file)

# Step 3: Save the preprocessed image as a .npy file
np.save('retinal_image.npy', image)

# Step 4: Build a CNN model for blood sugar prediction
def build_model(input_shape):
    model = models.Sequential([
        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(128, (3, 3), activation='relu'),
        layers.Flatten(),
        layers.Dense(128, activation='relu'),
        layers.Dense(1)
    ])
    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])
    return model

input_shape = image.shape[1:]
model = build_model(input_shape)

# Step 5: Load pre-trained weights (if available)
pretrained_model_path = 'pretrained_model.weights.h5'
try:
    model.load_weights(pretrained_model_path)
    print("Pre-trained model weights loaded successfully.")
except Exception as e:
    print(f"Warning: Could not load pre-trained weights. The model is untrained. Error: {e}")

# Step 6: Training the model with early stopping
X_train, y_train = np.random.rand(100, 68, 68, 3), np.random.rand(100) * 200  # Example data
X_val, y_val = np.random.rand(20, 68, 68, 3), np.random.rand(20) * 200  # Example data

early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stop])

# Step 7: Save the trained model
model.save_weights("trained_model.weights.h5")
print("\n✅ Model trained and saved as 'trained_model.weights.h5'.")

# Step 8: Predict blood sugar level
predicted_blood_sugar = model.predict(image)[0][0]
print(f"\nPredicted Blood Sugar Level: {predicted_blood_sugar:.2f} mg/dL")

# Step 9: Plot training loss and validation loss
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Step 10: Display the uploaded image
plt.imshow(image[0])
plt.title(f"Predicted Blood Sugar Level: {predicted_blood_sugar:.2f} mg/dL")
plt.axis('off')
plt.show()

# Import necessary libraries
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.callbacks import EarlyStopping
from google.colab import files

# Step 1: Upload a retinal image (JPEG format)
print("Please upload your retinal image (JPEG format).")
uploaded = files.upload()

if not uploaded:
    raise ValueError("No file uploaded. Please upload an image.")

image_file = list(uploaded.keys())[0]

# Step 2: Load and preprocess the image
def preprocess_image(image_path, target_size=(68, 68)):
    try:
        img = Image.open(image_path).convert('RGB')
        img = img.resize(target_size)
        img_array = np.array(img) / 255.0  # Normalize to [0, 1]
        img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension
        return img_array
    except Exception as e:
        raise ValueError(f"Error processing image: {e}")

# Preprocess the uploaded image
image = preprocess_image(image_file)
print("Image successfully processed.")

# Save preprocessed image
np.save('retinal_image.npy', image)

# Step 3: Define the blood sugar value range for scaling
min_value = 80  # Minimum blood sugar in dataset
max_value = 180  # Maximum blood sugar in dataset

# Step 4: Build an improved CNN model
def build_model(input_shape):
    model = models.Sequential([
        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(128, (3, 3), activation='relu'),
        layers.Flatten(),
        layers.Dense(128, activation='relu'),
        layers.Dense(1)  # Output layer for regression
    ])
    model.compile(optimizer='adam', loss='mean_absolute_error', metrics=['mae'])
    return model

# Define input shape
input_shape = image.shape[1:]

# Build and compile model
model = build_model(input_shape)

# Step 5: Load pre-trained weights if available
pretrained_model_path = 'trained_model.weights.h5'  # Corrected filename format

try:
    model.load_weights(pretrained_model_path)
    print("Pre-trained model weights loaded successfully.")
except Exception as e:
    print(f"Warning: Could not load pre-trained weights. Model will be trained from scratch. Error: {e}")

# Step 6: Train the model with Early Stopping
# (Ensure X_train, y_train, X_val, y_val are correctly prepared)
early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

history = model.fit(
    X_train, y_train,
    epochs=100, batch_size=32,
    validation_data=(X_val, y_val),
    callbacks=[early_stop]
)

# Step 7: Save the trained model weights
model.save_weights('trained_model.weights.h5')
print("✅ Model trained and saved as 'trained_model.weights.h5'.")

# Step 8: Predict the blood sugar level
predicted_blood_sugar = model.predict(image)[0][0]

# Step 9: Apply inverse scaling if needed
# predicted_blood_sugar = predicted_blood_sugar * (max_value - min_value) + min_value
# Step 9: Apply inverse scaling correction
predicted_blood_sugar = (predicted_blood_sugar * (max_value - min_value)) + min_value

# Ensure it stays within realistic range
predicted_blood_sugar = np.clip(predicted_blood_sugar, min_value, max_value)

# Display the result
print(f"\nPredicted Blood Sugar Level: {predicted_blood_sugar:.2f} mg/dL")

# Step 10: Plot training loss and validation loss
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.title("Training Progress")
plt.show()

# Step 11: Display the uploaded image with the predicted value
plt.imshow(image[0])
plt.title(f"Predicted Blood Sugar Level: {predicted_blood_sugar:.2f} mg/dL")
plt.axis('off')
plt.show()

# Import necessary libraries
import numpy as np
from PIL import Image
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.callbacks import EarlyStopping
from google.colab import files
import matplotlib.pyplot as plt

# Step 1: Upload a retinal image (JPEG format)
print("Please upload your retinal image (JPEG format).")
uploaded = files.upload()

if not uploaded:
    raise ValueError("No file uploaded. Please upload an image.")

# Get the uploaded file name
image_file = list(uploaded.keys())[0]

# Step 2: Load and preprocess the image
def preprocess_image(image_path, target_size=(68, 68)):
    try:
        img = Image.open(image_path).convert('RGB')  # Ensure RGB mode
        img = img.resize(target_size)
        img_array = np.array(img) / 255.0  # Normalize to [0, 1]
        img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension
        return img_array
    except Exception as e:
        raise ValueError(f"Error processing image: {e}")

# Preprocess the uploaded image
image = preprocess_image(image_file)

# Step 3: Save the preprocessed image as a .npy file
np.save('retinal_image.npy', image)

# Define blood sugar level normalization values
min_value = 80  # Example: Minimum blood sugar level in dataset
max_value = 180  # Example: Maximum blood sugar level in dataset

# Step 4: Build a CNN model for blood sugar prediction
def build_model(input_shape):
    model = models.Sequential([
        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(128, (3, 3), activation='relu'),
        layers.Flatten(),
        layers.Dense(128, activation='relu'),
        layers.Dense(1)  # Output layer for regression (predicting blood sugar level)
    ])
    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
                  loss='mean_squared_error',
                  metrics=['mae'])
    return model

input_shape = image.shape[1:]  # Shape of a single image (e.g., 68, 68, 3)
model = build_model(input_shape)

# Step 5: Load pre-trained weights (if available)
pretrained_model_path = 'pretrained_model.weights.h5'  # Ensure proper .weights.h5 extension

try:
    model.load_weights(pretrained_model_path)
    print("✅ Pre-trained model weights loaded successfully.")
except Exception as e:
    print(f"⚠ Warning: Could not load pre-trained weights. Model will be trained from scratch. Error: {e}")

# Step 6: Train the model (if no pre-trained weights)
# Load training dataset (replace with actual dataset)
X_train = np.random.rand(500, 68, 68, 3)  # Example dataset (500 random images)
y_train = np.random.randint(80, 180, 500)  # Example labels (random blood sugar values)

X_val = np.random.rand(100, 68, 68, 3)  # Validation dataset
y_val = np.random.randint(80, 180, 100)  # Validation labels

# Normalize labels
y_train = (y_train - min_value) / (max_value - min_value)
y_val = (y_val - min_value) / (max_value - min_value)

# Early stopping to prevent overfitting
early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# Train the model
history = model.fit(X_train, y_train, epochs=100, batch_size=32,
                    validation_data=(X_val, y_val), callbacks=[early_stop])

# Save trained model
model.save_weights('trained_model.weights.h5')
print("✅ Model trained and saved as 'trained_model.weights.h5'.")

# Step 7: Predict the blood sugar level
predicted_blood_sugar = model.predict(image)[0][0]

# Step 8: Apply inverse scaling correction
predicted_blood_sugar = (predicted_blood_sugar * (max_value - min_value)) + min_value
predicted_blood_sugar = np.clip(predicted_blood_sugar, min_value, max_value)  # Ensure realistic values

# Step 9: Display the result
print(f"\n🔹 Predicted Blood Sugar Level: {predicted_blood_sugar:.2f} mg/dL")

# Step 10: Plot training loss
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Step 11: Display the uploaded image
plt.imshow(image[0])  # Remove batch dimension for display
plt.title(f"Predicted Blood Sugar Level: {predicted_blood_sugar:.2f} mg/dL")
plt.axis('off')
plt.show()

# Import necessary libraries
import numpy as np
from PIL import Image
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.callbacks import EarlyStopping
from google.colab import files
import matplotlib.pyplot as plt

# Step 1: Upload a retinal image (JPEG format)
print("Please upload your retinal image (JPEG format).")
uploaded = files.upload()

if not uploaded:
    raise ValueError("No file uploaded. Please upload an image.")

# Get the uploaded file name
image_file = list(uploaded.keys())[0]

# Step 2: Load and preprocess the image
def preprocess_image(image_path, target_size=(68, 68)):
    try:
        img = Image.open(image_path).convert('RGB')  # Ensure RGB mode
        img = img.resize(target_size)
        img_array = np.array(img) / 255.0  # Normalize to [0, 1]
        img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension
        return img_array
    except Exception as e:
        raise ValueError(f"Error processing image: {e}")

# Preprocess the uploaded image
image = preprocess_image(image_file)

# Step 3: Save the preprocessed image as a .npy file
np.save('retinal_image.npy', image)

# Define blood sugar level normalization values
min_value = 80  # Example: Minimum blood sugar level in dataset
max_value = 180  # Example: Maximum blood sugar level in dataset

# Step 4: Build a CNN model for blood sugar prediction
def build_model(input_shape):
    model = models.Sequential([
        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(128, (3, 3), activation='relu'),
        layers.Flatten(),
        layers.Dense(128, activation='relu'),
        layers.Dense(1)  # Output layer for regression (predicting blood sugar level)
    ])
    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
                  loss='mean_squared_error',
                  metrics=['mae'])
    return model

input_shape = image.shape[1:]  # Shape of a single image (e.g., 68, 68, 3)
model = build_model(input_shape)

# Step 5: Load pre-trained weights (if available)
pretrained_model_path = 'pretrained_model.weights.h5'  # Ensure proper .weights.h5 extension

try:
    model.load_weights(pretrained_model_path)
    print("✅ Pre-trained model weights loaded successfully.")
except Exception as e:
    print(f"⚠ Warning: Could not load pre-trained weights. Model will be trained from scratch. Error: {e}")

# Step 6: Train the model (if no pre-trained weights)
# Load training dataset (replace with actual dataset)
X_train = np.random.rand(500, 68, 68, 3)  # Example dataset (500 random images)
y_train = np.random.randint(80, 180, 500)  # Example labels (random blood sugar values)

X_val = np.random.rand(100, 68, 68, 3)  # Validation dataset
y_val = np.random.randint(80, 180, 100)  # Validation labels

# Normalize labels
y_train = (y_train - min_value) / (max_value - min_value)
y_val = (y_val - min_value) / (max_value - min_value)

# Early stopping to prevent overfitting
early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# Train the model
history = model.fit(X_train, y_train, epochs=100, batch_size=32,
                    validation_data=(X_val, y_val), callbacks=[early_stop])

# Save trained model
model.save_weights('trained_model.weights.h5')
print("✅ Model trained and saved as 'trained_model.weights.h5'.")

# Step 7: Predict the blood sugar level
predicted_blood_sugar = model.predict(image)[0][0]

# Step 8: Apply inverse scaling correction
predicted_blood_sugar = (predicted_blood_sugar * (max_value - min_value)) + min_value
predicted_blood_sugar = np.clip(predicted_blood_sugar, min_value, max_value)  # Ensure realistic values

# Step 9: Display the result
print(f"\n🔹 Predicted Blood Sugar Level: {predicted_blood_sugar:.2f} mg/dL")

# Step 10: Plot training loss
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Step 11: Display the uploaded image
plt.imshow(image[0])  # Remove batch dimension for display
plt.title(f"Predicted Blood Sugar Level: {predicted_blood_sugar:.2f} mg/dL")
plt.axis('off')
plt.show()

# Import necessary libraries
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.callbacks import EarlyStopping
from google.colab import files
import matplotlib.pyplot as plt
from PIL import Image
import random
import os

# Step 1: Set seed for reproducibility
SEED = 42
np.random.seed(SEED)
tf.random.set_seed(SEED)
random.seed(SEED)
os.environ['PYTHONHASHSEED'] = str(SEED)

# Step 2: Upload a retinal image
print("Please upload your retinal image (JPEG format).")
uploaded = files.upload()

if not uploaded:
    raise ValueError("No file uploaded. Please upload an image.")

image_file = list(uploaded.keys())[0]

# Step 3: Load and preprocess the image
def preprocess_image(image_path, target_size=(68, 68)):
    try:
        img = Image.open(image_path).convert('RGB')  # Ensure RGB mode
        img = img.resize(target_size)
        img_array = np.array(img) / 255.0  # Normalize to [0, 1]
        img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension
        return img_array
    except Exception as e:
        raise ValueError(f"Error processing image: {e}")

image = preprocess_image(image_file)
print("Image successfully processed.")

# Step 4: Save the preprocessed image as a .npy file
np.save('retinal_image.npy', image)
print("Image saved as 'retinal_image.npy'.")

# Step 5: Prepare the dataset (Dummy dataset for training)
# Since we don’t have real data, we'll create random data for demonstration
num_samples = 1000
X_train = np.random.rand(num_samples, 68, 68, 3)
y_train = np.random.uniform(70, 200, num_samples)  # Simulating blood sugar levels

X_val = np.random.rand(200, 68, 68, 3)
y_val = np.random.uniform(70, 200, 200)

# Step 6: Build the CNN Model
def build_model(input_shape):
    model = models.Sequential([
        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(128, (3, 3), activation='relu'),
        layers.Flatten(),
        layers.Dense(128, activation='relu'),
        layers.Dense(1)  # Output layer for regression
    ])
    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])
    return model

input_shape = image.shape[1:]  # Shape of a single image (68, 68, 3)
model = build_model(input_shape)

# Step 7: Train the model with Early Stopping
early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

history = model.fit(
    X_train, y_train, epochs=100, batch_size=32,
    validation_data=(X_val, y_val), callbacks=[early_stop]
)

# Step 8: Plot training vs. validation loss
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Step 9: Predict the blood sugar level
model.trainable = False  # Freeze model to prevent changes
predicted_blood_sugar = model.predict(image, batch_size=1, verbose=0)[0][0]

# Step 10: Display the result
print(f"\nPredicted Blood Sugar Level: {predicted_blood_sugar:.2f} mg/dL")

# Step 11: Show the uploaded image with prediction
plt.imshow(image[0])  # Remove batch dimension for display
plt.title(f"Predicted Blood Sugar Level: {predicted_blood_sugar:.2f} mg/dL")
plt.axis('off')
plt.show()



# Import necessary libraries
import numpy as np
from PIL import Image
import tensorflow as tf
from tensorflow.keras import layers, models
from google.colab import files
import matplotlib.pyplot as plt
import cv2

# Install Real-ESRGAN (if not already installed)
!pip install realesrgan

from realesrgan import RealESRGAN

# Step 1: Upload a retinal image (JPEG format)
print("Please upload your retinal image (JPEG format).")
uploaded = files.upload()

# Check if any file was uploaded
if not uploaded:
    raise ValueError("No file uploaded. Please upload an image.")

# Get the uploaded file name
image_file = list(uploaded.keys())[0]

# Step 2: Load and preprocess the image
def preprocess_image(image_path, target_size=(68, 68)):
    try:
        img = Image.open(image_path).convert('RGB')  # Ensure RGB mode
        img = img.resize(target_size)
        img_array = np.array(img) / 255.0  # Normalize to [0, 1]
        img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension
        return img, img_array
    except Exception as e:
        raise ValueError(f"Error processing image: {e}")

# Preprocess the uploaded image
try:
    original_img, image = preprocess_image(image_file)
    print("Image successfully processed.")
except Exception as e:
    print(f"Error: {e}")
    raise

# Step 3: Apply Real-ESRGAN for Image Enhancement
def enhance_image(image_path):
    try:
        model = RealESRGAN("cuda")  # Use GPU for faster processing
        model.load_weights("weights/RealESRGAN_x4.pth", download=True)  # Load pretrained model
        img = Image.open(image_path).convert("RGB")
        sr_image = model.predict(img)  # Super-resolved image
        return sr_image
    except Exception as e:
        print(f"Error enhancing image: {e}")
        return None

# Enhance the image
enhanced_img = enhance_image(image_file)

if enhanced_img:
    enhanced_img.save("enhanced_retinal_image.jpg")
    print("Enhanced image saved as 'enhanced_retinal_image.jpg'.")
    enhanced_img = enhanced_img.resize((68, 68))  # Resize for CNN input
    enhanced_array = np.array(enhanced_img) / 255.0
    enhanced_array = np.expand_dims(enhanced_array, axis=0)
else:
    print("Using original image for prediction.")
    enhanced_array = image

# Step 4: Save the preprocessed image as a .npy file
np.save('retinal_image.npy', enhanced_array)
print("Image saved as 'retinal_image.npy'.")

# Step 5: Build a CNN model for blood sugar prediction
def build_model(input_shape):
    model = models.Sequential([
        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(128, (3, 3), activation='relu'),
        layers.Flatten(),
        layers.Dense(128, activation='relu'),
        layers.Dense(1)  # Output layer for regression (predicting blood sugar level)
    ])
    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])
    return model

# Define input shape based on the preprocessed image
input_shape = enhanced_array.shape[1:]

# Build the model
model = build_model(input_shape)

# Step 6: Load pre-trained weights (if available)
pretrained_model_path = 'pretrained_model.h5'  # Change this to your trained model file

try:
    model.load_weights(pretrained_model_path)
    print("Pre-trained model weights loaded successfully.")
except Exception as e:
    print(f"Warning: Could not load pre-trained weights. The model is untrained. Error: {e}")

# Step 7: Predict the blood sugar level
predicted_blood_sugar = model.predict(enhanced_array)[0][0]

# Step 8: Display the result
print(f"\nPredicted Blood Sugar Level: {predicted_blood_sugar:.2f} mg/dL")

# Step 9: Display the original and enhanced images
fig, axes = plt.subplots(1, 2, figsize=(10, 5))
axes[0].imshow(original_img)
axes[0].set_title("Original Image")
axes[0].axis("off")

if enhanced_img:
    axes[1].imshow(enhanced_img)
    axes[1].set_title(f"Enhanced Image (HD)")
    axes[1].axis("off")

plt.show()

import torch
print(torch.cuda.is_available())  # Should return True if GPU is enabled

import torch
print(torch.cuda.is_available())

!nvidia-smi

!nvidia-smi

import cv2
import os
import matplotlib.pyplot as plt

# Set your image path
image_path = "path/to/your/image.jpg"  # Change to actual image path

# Check if the image exists
if not os.path.exists(image_path):
    print("❌ Error: Image file not found! Check the path.")
else:
    # Load the image and resize it to 512x512 for faster processing
    image = cv2.imread(image_path)
    image = cv2.resize(image, (512, 512))

    # Convert to grayscale (optional)
    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # Save grayscale image (optional)
    cv2.imwrite("grayscale_image.jpg", gray_image)

    # Show both images
    plt.figure(figsize=(10, 5))

    plt.subplot(1, 2, 1)
    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    plt.title("Resized Original Image")

    plt.subplot(1, 2, 2)
    plt.imshow(gray_image, cmap='gray')
    plt.title("Grayscale Image (Saved as 'grayscale_image.jpg')")

    plt.show()

print("✅ Processing Done!")

from google.colab import files
uploaded = files.upload()

import os
print(os.listdir("/content/"))  # Check if the dataset is inside /content/
print(os.listdir("/content/kaggle/train_images/"))  # Adjust the path if needed

from google.colab import files
files.upload()  # Select kaggle.json when prompted

from google.colab import files
files.upload()  # Select kaggle.json when prompted



#✅ Step 1: Move kaggle.json to the Correct Folder
# Run this to move and set permissions:
import os
os.makedirs("/root/.kaggle", exist_ok=True)
!mv kaggle.json /root/.kaggle/
!chmod 600 /root/.kaggle/kaggle.json  # Secure API key

import os
print(os.listdir("/content/"))

from google.colab import files
files.upload()  # Select kaggle.json when prompted

!ls /content/

!ls -l /content/kaggle.json

!rm -f /content/kaggle.json
from google.colab import files
files.upload()
!mkdir -p /root/.kaggle
!mv /content/kaggle.json /root/.kaggle/
!chmod 600 /root/.kaggle/kaggle.json
!ls -1 /root/.kaggle/

from google.colab import files
files.upload()  # Select kaggle.json when prompted
import os
os.makedirs("/root/.kaggle", exist_ok=True)
!mv /content/kaggle.json /root/.kaggle/
!chmod 600 /root/.kaggle/kaggle.json  # Secure API key
print(os.listdir("/root/.kaggle/"))
# !kaggle datasets download -d arvindnarayanaswamy/aptos2019-blindness-detection
print(os.listdir("/content/"))
!mv /content/kaggle\ \(1\).json /content/kaggle.json
print(os.listdir("/content/"))
import os
os.makedirs("/root/.kaggle", exist_ok=True)
!mv /content/kaggle.json /root/.kaggle/
!chmod 600 /root/.kaggle/kaggle.json  # Secure API key
print(os.listdir("/root/.kaggle/"))

!kaggle datasets download -d arvindnarayanaswamy/aptos2019-blindness-detection

from google.colab import files
files.upload()  # Select kaggle.json when prompted
import os
os.makedirs("/root/.kaggle", exist_ok=True)
!mv /content/kaggle.json /root/.kaggle/
!chmod 600 /root/.kaggle/kaggle.json  # Secure API key
print(os.listdir("/root/.kaggle/"))
# !kaggle datasets download -d arvindnarayanaswamy/aptos2019-blindness-detection
print(os.listdir("/content/"))
!mv /content/kaggle\ \(1\).json /content/kaggle.json
print(os.listdir("/content/"))
import os
os.makedirs("/root/.kaggle", exist_ok=True)
!mv /content/kaggle.json /root/.kaggle/
!chmod 600 /root/.kaggle/kaggle.json  # Secure API key
print(os.listdir("/root/.kaggle/"))

!kaggle datasets list
!kaggle datasets download -d arvindnarayanaswamy/aptos2019-blindness-detection

from google.colab import files
uploaded = files.upload()

!kaggle datasets download -d arvindnarayanaswamy/aptos2019-blindness-detection

!pip install kaggle

from google.colab import files
import os
# Upload kaggle.json
files.upload()
!mv /content/kaggle.json /root/.kaggle/
!chmod 600 /root/.kaggle/kaggle.json  # Secure API key
print(os.listdir("/root/.kaggle/"))

from google.colab import files
files.upload()
import shutil

# Rename the file to kaggle.json
shutil.move("kaggle (1) (4).json", "kaggle.json")

# Move it to the correct directory
!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# Verify the file exists in the correct location
import os
print(os.listdir("/root/.kaggle/"))  # Should show ['kaggle.json']

!kaggle datasets download -d arvindnarayanaswamy/aptos2019-blindness-detection

!kaggle datasets list

from google.colab import files

# Upload the dataset ZIP file
uploaded = files.upload()

import os
os.makedirs("/root/.kaggle", exist_ok=True)
!mv /content/kaggle.json /root/.kaggle/
!chmod 600 /root/.kaggle/kaggle.json  # Secure API key

from google.colab import drive
drive.mount('/content/drive')

!ls /content/drive/MyDrive/

!ls "/content/drive/MyDrive/"

!unzip "/content/drive/MyDrive/train_images.zip" -d "/content/drive/MyDrive/train_images"

from google.colab import drive
drive.mount('/content/drive')

import os
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import Adam

!unzip "/content/drive/MyDrive/train_images.zip" -d "/content/drive/MyDrive/train_images"

dataset_path = "/content/drive/MyDrive/train_images/"  # Update this if needed

# Check if dataset exists
if os.path.exists(dataset_path):
    print("Dataset found!")
    print("Contents:", os.listdir(dataset_path))
else:
    print("Dataset path not found. Check the path again.")

# Define image properties
IMG_SIZE = (224, 224)
BATCH_SIZE = 32

# Data Augmentation & Image Preprocessing
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    validation_split=0.2  # 80% Train, 20% Validation
)

train_generator = train_datagen.flow_from_directory(
    dataset_path,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='binary',
    subset='training'
)

val_generator = train_datagen.flow_from_directory(
    dataset_path,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='binary',
    subset='validation'
)

pip install tensorflow keras

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator  # Correct import

!unzip -o "/content/drive/MyDrive/train_images.zip" -d "/content/drive/MyDrive/train_images/"

import os

dataset_path = "/content/drive/MyDrive/train_images/train_images"  # Update if needed
print("Does the dataset path exist?", os.path.exists(dataset_path))
print("Files inside:", os.listdir(dataset_path)[:5])  # Show some files

import os
import shutil

dataset_path = "/content/drive/MyDrive/train_images/train_images"
class1_path = os.path.join(dataset_path, "class_1")
class2_path = os.path.join(dataset_path, "class_2")

# Create subfolders if they don't exist
os.makedirs(class1_path, exist_ok=True)
os.makedirs(class2_path, exist_ok=True)

# Move first half of images to class_1, rest to class_2 (Modify as needed)
all_images = [f for f in os.listdir(dataset_path) if f.endswith((".png", ".jpg", ".jpeg"))]
for i, img in enumerate(all_images):
    src = os.path.join(dataset_path, img)
    dest = os.path.join(class1_path if i % 2 == 0 else class2_path, img)
    shutil.move(src, dest)

print("Images organized into class_1 and class_2!")

# Define the correct dataset path (now with class folders)
dataset_path = "/content/drive/MyDrive/train_images/train_images"

# Define image size and batch size
IMG_SIZE = (224, 224)
BATCH_SIZE = 32

# Image Preprocessing
from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    validation_split=0.2  # Splitting 20% for validation
)

# Load training images
train_generator = train_datagen.flow_from_directory(
    dataset_path,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode="binary",
    subset="training"
)

# Load validation images
val_generator = train_datagen.flow_from_directory(
    dataset_path,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode="binary",
    subset="validation"
)

!find /content/drive/MyDrive/ -name "*.csv"

import os
import pandas as pd

# Define the dataset path
dataset_path = "/content/drive/MyDrive/train_images/"

# List all image files
image_files = [f for f in os.listdir(dataset_path) if f.endswith(".png")]

# Create a DataFrame with filenames
df = pd.DataFrame({"Image Name": image_files})

# Save it as CSV
csv_path = os.path.join(dataset_path, "train.csv")
df.to_csv(csv_path, index=False)

print("CSV file created successfully at:", csv_path)

import os
import pandas as pd
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import Adam

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Define dataset paths
dataset_path = "/content/drive/MyDrive/train_images/"
csv_path = "/content/drive/MyDrive/train.csv"  # Update with actual file path

# Load CSV
df = pd.read_csv(csv_path)
df['image_path'] = dataset_path + df['Image Name']  # Full path to images

# Show dataset preview
print(df.head())

import os

csv_folder = "/content/drive/MyDrive/train_images"  # Folder where CSV should be
print("Files in the directory:", os.listdir(csv_folder))

import pandas as pd

csv_path = "/content/drive/MyDrive/train_images/train.csv"  # Path to your CSV

df = pd.read_csv(csv_path)
print(df.head())  # Display the first few rows

import os

dataset_path = "/content/drive/MyDrive/train_images/"  # Ensure this ends with "/"
df["image_path"] = df["Image Name"].apply(lambda x: os.path.join(dataset_path, x))

print(df.head())  # Check if image paths are correct

from sklearn.model_selection import train_test_split

# Assuming no labels exist yet, just splitting images
train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)

print("Training Data:", train_df.shape)
print("Validation Data:", val_df.shape)

from tensorflow.keras.preprocessing.image import ImageDataGenerator

IMG_SIZE = (224, 224)  # Resize all images to this size
BATCH_SIZE = 32

# Data Augmentation & Normalization
train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)

train_generator = train_datagen.flow_from_dataframe(
    dataframe=train_df,
    x_col="image_path",
    y_col=None,  # Update this if you have labels
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode=None,  # Use 'binary' or 'categorical' if labels exist
    shuffle=True
)

val_generator = train_datagen.flow_from_dataframe(
    dataframe=val_df,
    x_col="image_path",
    y_col=None,  # Update this if you have labels
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode=None,
    shuffle=False
)

print("Data Preprocessing Done!")

if "Label" in df.columns:
    print(df["Label"].value_counts())  # Count images in each class
else:
    print("❌ No 'Label' column found in CSV! Check your dataset.")

from tensorflow.keras.preprocessing.image import ImageDataGenerator

dataset_path = "/content/drive/MyDrive/train_images/"
IMG_SIZE = (224, 224)
BATCH_SIZE = 32

train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)

train_generator = train_datagen.flow_from_directory(
    dataset_path,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode="binary",  # Use "categorical" if more than 2 classes
    subset="training"
)

val_generator = train_datagen.flow_from_directory(
    dataset_path,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode="binary",
    subset="validation"
)

print("Classes Found:", train_generator.class_indices)

import pandas as pd

# Load CSV
csv_path = "/content/drive/MyDrive/train_images/train.csv"
df = pd.read_csv(csv_path)

# Manually create a dictionary of labels (update this based on your dataset)
label_dict = {
    "6fb656d506b2.png": "class_1",
    "6fe4751a3b42.png": "class_2",
    "6fbaaf8eb67a.png": "class_1",
    "7005be54cab1.png": "class_2",
    "702de9dcde32.png": "class_1",
    # Add more images and labels here
}

# Assign labels to the DataFrame
df["Label"] = df["Image Name"].map(label_dict)

# Drop rows where Label is missing
df = df.dropna()

# Save the updated CSV
df.to_csv(csv_path, index=False)

print("✅ Updated train.csv with class labels!")
print(df.head())  # Preview the updated CSV

import os
import pandas as pd

# Define dataset path
dataset_path = "/content/drive/MyDrive/train_images/"

# Get image names and their corresponding labels (folder names)
data = []
for class_name in ["class_1", "class_2"]:
    class_path = os.path.join(dataset_path, class_name)
    if os.path.exists(class_path):
        for image_name in os.listdir(class_path):
            if image_name.endswith(".png") or image_name.endswith(".jpg"):
                data.append({"Image Name": image_name, "Label": class_name})

# Convert to DataFrame
df = pd.DataFrame(data)

# Save to CSV
csv_path = "/content/drive/MyDrive/train_images/train.csv"
df.to_csv(csv_path, index=False)

print("✅ CSV file updated with labels based on folder names!")
print(df.head())  # Preview the updated CSV

!ls -R /content/drive/MyDrive/train_images/

import pandas as pd

# Define the CSV path
csv_path = "/content/drive/MyDrive/train_images/train.csv"

# Load CSV
df = pd.read_csv(csv_path)

# Check if 'Label' column exists
if "Label" not in df.columns:
    print("❌ No 'Label' column found! You must manually add class labels.")

# Display first few rows
print(df.head())

!ls -lh /content/drive/MyDrive/train_images/train.csv

import os
import pandas as pd

# Define dataset path
dataset_path = "/content/drive/MyDrive/train_images/"

# Check if images exist
image_files = [f for f in os.listdir(dataset_path) if f.endswith((".png", ".jpg"))]

# If no images are found, print an error
if not image_files:
    print("❌ No images found in the dataset folder! Check your dataset path.")
else:
    # Manually assign labels (modify this based on your dataset)
    labels = ["class_1" if i % 2 == 0 else "class_2" for i in range(len(image_files))]

    # Create DataFrame
    df = pd.DataFrame({"Image Name": image_files, "Label": labels})

    # Save to CSV
    csv_path = "/content/drive/MyDrive/train_images/train.csv"
    df.to_csv(csv_path, index=False)

    print("✅ CSV file created successfully!")
    print(df.head())  # Preview CSV

import pandas as pd

# Load CSV file
csv_path = "/content/drive/MyDrive/train_images/train.csv"
df = pd.read_csv(csv_path)

# Count number of images per class
class_distribution = df["Label"].value_counts()

# Print results
print("✅ Class Distribution:")
print(class_distribution)

import os

csv_path = "/content/drive/MyDrive/train_images/train.csv"

if os.path.exists(csv_path):
    print("✅ CSV file exists!")
else:
    print("❌ CSV file is missing! Check the path.")

with open(csv_path, "r") as f:
    content = f.read()

if content.strip():
    print("✅ CSV file is not empty.")
else:
    print("❌ CSV file is empty! Try recreating it.")

import pandas as pd

# Define image labels (recreate your CSV)
data = {
    "Image Name": ["6fb656d506b2.png", "6fe4751a3b42.png", "6fbaaf8eb67a.png"],
    "Label": ["class_1", "class_2", "class_1"]  # Adjust based on your dataset
}

df = pd.DataFrame(data)

# Save CSV again
csv_path = "/content/drive/MyDrive/train_images/train.csv"
df.to_csv(csv_path, index=False)
print("✅ CSV file recreated successfully!")

import pandas as pd

# Define CSV path
csv_path = "/content/drive/MyDrive/train_images/train.csv"

# Load CSV
df = pd.read_csv(csv_path)

# Display first few rows
print(df.head())

# Check if 'Label' column exists
if "Label" in df.columns:
    print("✅ 'Label' column detected! Ready for training.")
else:
    print("❌ No 'Label' column found! Check your CSV file.")

import tensorflow as tf
import numpy as np
import os
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.preprocessing.image import load_img, img_to_array

# Image settings
IMG_SIZE = (224, 224)  # Resize all images to 224x224
dataset_path = "/content/drive/MyDrive/train_images/"

# Load images and labels
X = []
y = []

for _, row in df.iterrows():
    img_path = os.path.join(dataset_path, row["Image Name"])
    img = load_img(img_path, target_size=IMG_SIZE)  # Load and resize image
    img_array = img_to_array(img) / 255.0  # Normalize pixel values
    X.append(img_array)

    # Convert labels to numeric values (class_1 -> 0, class_2 -> 1)
    y.append(0 if row["Label"] == "class_1" else 1)

# Convert to NumPy arrays
X = np.array(X)
y = np.array(y)

# One-hot encode labels
y = to_categorical(y, num_classes=2)

# Print dataset shape
print(f"✅ Dataset Loaded: {X.shape}, Labels: {y.shape}")

import os

missing_files = []

for img_name in df["Image Name"]:
    img_path = os.path.join(dataset_path, img_name)
    if not os.path.exists(img_path):
        missing_files.append(img_name)

if missing_files:
    print(f"❌ Missing images detected: {len(missing_files)} files")
    print(missing_files[:10])  # Show first 10 missing files
else:
    print("✅ All image files are present!")

from PIL import Image

corrupt_files = []

for img_name in df["Image Name"]:
    img_path = os.path.join(dataset_path, img_name)
    try:
        with Image.open(img_path) as img:
            img.verify()  # Verify if the image is valid
    except Exception:
        corrupt_files.append(img_name)

if corrupt_files:
    print(f"❌ Corrupt images detected: {len(corrupt_files)} files")
    print(corrupt_files[:10])  # Show first 10 corrupted files
else:
    print("✅ All images are valid!")

# Remove corrupt images from DataFrame
df = df[~df["Image Name"].isin(corrupt_files)]

# Save the updated CSV
df.to_csv(csv_path, index=False)
print("✅ Updated CSV file without corrupt images!")

from PIL import Image

corrupt_files = []

for img_name in df["Image Name"]:
    img_path = os.path.join(dataset_path, img_name)
    try:
        with Image.open(img_path) as img:
            img.verify()  # Verify if the image is valid
    except Exception:
        corrupt_files.append(img_name)

if corrupt_files:
    print(f"❌ Corrupt images detected: {len(corrupt_files)} files")
    print(corrupt_files[:10])  # Show first 10 corrupted files
else:
    print("✅ All images are valid!")

import tensorflow as tf
import numpy as np
import os
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.preprocessing.image import load_img, img_to_array

# Image settings
IMG_SIZE = (224, 224)  # Resize all images to 224x224
dataset_path = "/content/drive/MyDrive/train_images/"

# Load images and labels
X = []
y = []

for _, row in df.iterrows():
    img_path = os.path.join(dataset_path, row["Image Name"])
    img = load_img(img_path, target_size=IMG_SIZE)  # Load and resize image
    img_array = img_to_array(img) / 255.0  # Normalize pixel values
    X.append(img_array)

    # Convert labels to numeric values (class_1 -> 0, class_2 -> 1)
    y.append(0 if row["Label"] == "class_1" else 1)

# Convert to NumPy arrays
X = np.array(X)
y = np.array(y)

# One-hot encode labels
y = to_categorical(y, num_classes=2)

# Print dataset shape
print(f"✅ Dataset Loaded: {X.shape}, Labels: {y.shape}")

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import Adam

# Create CNN Model
model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(224, 224, 3)),
    MaxPooling2D(2,2),

    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),

    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(2, activation='softmax')  # 2 classes (class_1, class_2)
])

# Compile model
model.compile(optimizer=Adam(learning_rate=0.001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Train model
model.fit(X, y, epochs=10, batch_size=32, validation_split=0.2)

print("✅ Model Training Completed!")

print(f"Total images loaded: {len(X)}")
print(f"Total labels loaded: {len(y)}")

print(df.head())  # Check the CSV structure
print(df.columns)  # Ensure correct column names